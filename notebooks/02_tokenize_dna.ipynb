{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d323c0c-226b-4bfc-9597-434bac7f303c",
   "metadata": {},
   "source": [
    "# Tokenize DNA using Byte-Pair Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189d9926-2bc9-402d-94b1-4b02dbd1b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e1db56-3340-48a6-b5ef-8a5a97030e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from adna.pylib import consts, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e3ac4b-ea8b-4fc5-baf8-1961ebad0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL = consts.DATA_DIR / 'UF46992.sqlite'\n",
    "JSON = consts.DATA_DIR / 'UF46992.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d2a94-cded-44f8-8515-604dfa165e47",
   "metadata": {},
   "source": [
    "## What characters are used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0f387b-48fd-4635-8209-34700c66a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(SQL) as cxn:\n",
    "    RECS = pd.read_sql('select * from seqs', cxn)\n",
    "\n",
    "SEQS = RECS.seq.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c8bcb7-18f1-4b41-92ec-744769deac9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 10996536/10996536 [00:20<00:00, 525776.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A', 'C', 'G', 'N', 'T'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHARS = set()\n",
    "\n",
    "for seq in tqdm(SEQS):\n",
    "    CHARS |= set(seq)\n",
    "\n",
    "CHARS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c50dc-f474-45ab-b6e3-2b946de3d30c",
   "metadata": {},
   "source": [
    "## Train the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5981dcf-6724-4a98-91ee-4a35353a4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer = BpeTrainer(\n",
    "    special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"],\n",
    "    vocab_size=5000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e57126c-a016-4fe3-b15d-0e311ce7b846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train_from_iterator(SEQS, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4737904-86e2-4d8e-bf8c-82b8aa5ba1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"[CLS] $A [SEP]\",\n",
    "    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
    "        (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c82b62c-2b63-4c63-a3b6-d53bfb2fe6a6",
   "metadata": {},
   "source": [
    "## Get tokenized lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "febedb2c-0407-4a47-a758-da4228356e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 10739/10739 [01:30<00:00, 119.00it/s]\n"
     ]
    }
   ],
   "source": [
    "lengths = defaultdict(int)\n",
    "\n",
    "step = 1024\n",
    "\n",
    "for i in tqdm(range(0, len(SEQS), step)):\n",
    "    batch = tokenizer.encode_batch(SEQS[i:i+step])\n",
    "    for tokens in batch:\n",
    "        t_len = len(tokens)\n",
    "        lengths[t_len] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e8db386-f7d6-47a3-b704-f0cabe7fceb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 844547),\n",
       " (4, 65580),\n",
       " (5, 239649),\n",
       " (6, 718210),\n",
       " (7, 847881),\n",
       " (8, 1066093),\n",
       " (9, 931242),\n",
       " (10, 919286),\n",
       " (11, 840813),\n",
       " (12, 730912),\n",
       " (13, 649932),\n",
       " (14, 544110),\n",
       " (15, 458988),\n",
       " (16, 380684),\n",
       " (17, 281347),\n",
       " (18, 238359),\n",
       " (19, 202386),\n",
       " (20, 155055),\n",
       " (21, 145031),\n",
       " (22, 102106),\n",
       " (23, 93519),\n",
       " (24, 70161),\n",
       " (25, 64585),\n",
       " (26, 57145),\n",
       " (27, 40983),\n",
       " (28, 32919),\n",
       " (29, 21221),\n",
       " (30, 26665),\n",
       " (31, 25962),\n",
       " (32, 15130),\n",
       " (33, 16515),\n",
       " (34, 16059),\n",
       " (35, 5741),\n",
       " (36, 5074),\n",
       " (37, 8417),\n",
       " (38, 6731),\n",
       " (39, 13284),\n",
       " (40, 4703),\n",
       " (41, 3560),\n",
       " (42, 6248),\n",
       " (43, 7718),\n",
       " (44, 4595),\n",
       " (45, 4591),\n",
       " (46, 3962),\n",
       " (47, 4510),\n",
       " (48, 5362),\n",
       " (49, 4394),\n",
       " (50, 5716),\n",
       " (51, 9894),\n",
       " (52, 5188),\n",
       " (53, 3180),\n",
       " (54, 3074),\n",
       " (55, 1726),\n",
       " (56, 2779),\n",
       " (57, 7124),\n",
       " (58, 1530),\n",
       " (59, 1259),\n",
       " (60, 3425),\n",
       " (61, 4432),\n",
       " (62, 5918),\n",
       " (63, 3422),\n",
       " (64, 955),\n",
       " (65, 866),\n",
       " (66, 1846),\n",
       " (67, 891),\n",
       " (68, 531),\n",
       " (69, 70),\n",
       " (70, 63),\n",
       " (71, 594),\n",
       " (72, 79),\n",
       " (73, 6),\n",
       " (74, 2),\n",
       " (75, 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lengths.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b4df33-fc3c-4d39-aebd-e253a83c059a",
   "metadata": {},
   "source": [
    "## Finalize tokenizer length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7770b5dc-d998-4c46-9d56-d04ce497442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_id = tokenizer.token_to_id(\"[PAD]\")\n",
    "tokenizer.enable_padding(pad_id=pad_id, length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03dc04a0-9d38-4ff6-a39c-881c23ccd6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'GGG',\n",
       " 'TG',\n",
       " 'CACTAATAACTAGCTCAGTGTG',\n",
       " 'TCTACGCCAAATTGACCTAAAATCACTCATCGCC',\n",
       " 'TACTCC',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer.encode(SEQS[0])\n",
    "output.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1080bf98-33d4-4526-a97d-62918c38a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(str(JSON))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9f96a-44d4-42b0-9927-6d6a745548ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb11a3-6965-41a7-8721-10653655f619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
